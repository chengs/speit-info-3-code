{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 3+4 Models in Docker\n",
    "\n",
    "该Example展示了如何使用一个model提供*实时预测*服务，包括两种部署方式\n",
    "\n",
    "* 使用Flask+Tensorflow部署\n",
    "* 使用Tensorflow Serving部署\n",
    "\n",
    "本Notebook当中比较了两种部署方式的性能，可以看到，\n",
    "同样的tensorflow模型，使用Tensorflow Serving的部署方式具有显著的性能优势"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 训练一个模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Survived  Pclass  \\\n",
       "PassengerId                     \n",
       "1                   0       3   \n",
       "2                   1       1   \n",
       "3                   1       3   \n",
       "4                   1       1   \n",
       "5                   0       3   \n",
       "\n",
       "                                                          Name     Sex   Age  \\\n",
       "PassengerId                                                                    \n",
       "1                                      Braund, Mr. Owen Harris    male  22.0   \n",
       "2            Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0   \n",
       "3                                       Heikkinen, Miss. Laina  female  26.0   \n",
       "4                 Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0   \n",
       "5                                     Allen, Mr. William Henry    male  35.0   \n",
       "\n",
       "             SibSp  Parch            Ticket     Fare Cabin Embarked  \n",
       "PassengerId                                                          \n",
       "1                1      0         A/5 21171   7.2500   NaN        S  \n",
       "2                1      0          PC 17599  71.2833   C85        C  \n",
       "3                0      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "4                1      0            113803  53.1000  C123        S  \n",
       "5                0      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load titanic data\n",
    "# https://www.kaggle.com/c/titanic/data\n",
    "train_data = pd.read_csv('./titanic_train.csv',index_col=0)\n",
    "train_data['Embarked'] = train_data['Embarked'].astype(str)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'Age': <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=float32>, 'Fare': <tf.Tensor 'ExpandDims_2:0' shape=(None, 1) dtype=float32>, 'Embarked': <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=string>, 'Sex': <tf.Tensor 'ExpandDims_4:0' shape=(None, 1) dtype=string>, 'Pclass': <tf.Tensor 'ExpandDims_3:0' shape=(None, 1) dtype=int64>}\n",
      "Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'Age': <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=float32>, 'Fare': <tf.Tensor 'ExpandDims_2:0' shape=(None, 1) dtype=float32>, 'Embarked': <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=string>, 'Sex': <tf.Tensor 'ExpandDims_4:0' shape=(None, 1) dtype=string>, 'Pclass': <tf.Tensor 'ExpandDims_3:0' shape=(None, 1) dtype=int64>}\n",
      "Consider rewriting this model with the Functional API.\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 2.4243\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_features (DenseFeature multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                multiple                  384       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              multiple                  33        \n",
      "=================================================================\n",
      "Total params: 417\n",
      "Trainable params: 417\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# train a keras model\n",
    "# with tensorflow features\n",
    "\n",
    "# define features\n",
    "features = [\n",
    "    tf.feature_column.numeric_column('Age', default_value=train_data.Age.mean()),\n",
    "    tf.feature_column.numeric_column('Fare', default_value=train_data.Fare.mean()),\n",
    "    tf.feature_column.indicator_column(\n",
    "        tf.feature_column.categorical_column_with_vocabulary_list('Embarked', train_data.Embarked.unique()),\n",
    "    ),\n",
    "    tf.feature_column.indicator_column(\n",
    "        tf.feature_column.categorical_column_with_vocabulary_list('Sex', train_data.Sex.unique()),\n",
    "    ),\n",
    "    tf.feature_column.indicator_column(\n",
    "        tf.feature_column.categorical_column_with_identity('Pclass', num_buckets=train_data.Pclass.max()),\n",
    "    )\n",
    "]\n",
    "\n",
    "feature_layer = keras.layers.DenseFeatures(features)\n",
    "\n",
    "model = keras.Sequential([\n",
    "    feature_layer,\n",
    "    keras.layers.Dense(32, activation='relu'),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='Adam')\n",
    "\n",
    "X = train_data[[\n",
    "    'Age','Fare','Embarked','Sex','Pclass'\n",
    "]].to_dict('series')\n",
    "\n",
    "for key in X:\n",
    "    if X[key].dtype == np.float32 or X[key].dtype == np.float64:\n",
    "        X[key] = X[key].fillna(X[key].mean()).values\n",
    "    else:\n",
    "        X[key] = X[key].values\n",
    "    \n",
    "y = train_data.Survived.values\n",
    "\n",
    "model.fit(X,y)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'Age': <tf.Tensor 'Age:0' shape=(None, 1) dtype=float32>, 'Fare': <tf.Tensor 'Fare:0' shape=(None, 1) dtype=float32>, 'Embarked': <tf.Tensor 'Embarked:0' shape=(None, 1) dtype=string>, 'Sex': <tf.Tensor 'Sex:0' shape=(None, 1) dtype=string>, 'Pclass': <tf.Tensor 'Pclass:0' shape=(None, 1) dtype=int64>}\n",
      "Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'Age': <tf.Tensor 'Age:0' shape=(None, 1) dtype=float32>, 'Fare': <tf.Tensor 'Fare:0' shape=(None, 1) dtype=float32>, 'Embarked': <tf.Tensor 'Embarked:0' shape=(None, 1) dtype=string>, 'Sex': <tf.Tensor 'Sex:0' shape=(None, 1) dtype=string>, 'Pclass': <tf.Tensor 'Pclass:0' shape=(None, 1) dtype=int64>}\n",
      "Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'Age': <tf.Tensor 'Age:0' shape=(None, 1) dtype=float32>, 'Fare': <tf.Tensor 'Fare:0' shape=(None, 1) dtype=float32>, 'Embarked': <tf.Tensor 'Embarked:0' shape=(None, 1) dtype=string>, 'Sex': <tf.Tensor 'Sex:0' shape=(None, 1) dtype=string>, 'Pclass': <tf.Tensor 'Pclass:0' shape=(None, 1) dtype=int64>}\n",
      "Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'Age': <tf.Tensor 'inputs:0' shape=(None, 1) dtype=float32>, 'Fare': <tf.Tensor 'inputs_2:0' shape=(None, 1) dtype=float32>, 'Embarked': <tf.Tensor 'inputs_1:0' shape=(None, 1) dtype=string>, 'Sex': <tf.Tensor 'inputs_4:0' shape=(None, 1) dtype=string>, 'Pclass': <tf.Tensor 'inputs_3:0' shape=(None, 1) dtype=int64>}\n",
      "Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'Age': <tf.Tensor 'inputs:0' shape=(None, 1) dtype=float32>, 'Fare': <tf.Tensor 'inputs_2:0' shape=(None, 1) dtype=float32>, 'Embarked': <tf.Tensor 'inputs_1:0' shape=(None, 1) dtype=string>, 'Sex': <tf.Tensor 'inputs_4:0' shape=(None, 1) dtype=string>, 'Pclass': <tf.Tensor 'inputs_3:0' shape=(None, 1) dtype=int64>}\n",
      "Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:From /Users/guchen/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From /Users/guchen/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'Age': <tf.Tensor 'inputs/Age:0' shape=(None, 1) dtype=float32>, 'Fare': <tf.Tensor 'inputs/Fare:0' shape=(None, 1) dtype=float32>, 'Embarked': <tf.Tensor 'inputs/Embarked:0' shape=(None, 1) dtype=string>, 'Sex': <tf.Tensor 'inputs/Sex:0' shape=(None, 1) dtype=string>, 'Pclass': <tf.Tensor 'inputs/Pclass:0' shape=(None, 1) dtype=int64>}\n",
      "Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'Age': <tf.Tensor 'inputs/Age:0' shape=(None, 1) dtype=float32>, 'Fare': <tf.Tensor 'inputs/Fare:0' shape=(None, 1) dtype=float32>, 'Embarked': <tf.Tensor 'inputs/Embarked:0' shape=(None, 1) dtype=string>, 'Sex': <tf.Tensor 'inputs/Sex:0' shape=(None, 1) dtype=string>, 'Pclass': <tf.Tensor 'inputs/Pclass:0' shape=(None, 1) dtype=int64>}\n",
      "Consider rewriting this model with the Functional API.\n",
      "INFO:tensorflow:Assets written to: ./tf_serving/model/assets\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'Age': <tf.Tensor 'Age:0' shape=(None, 1) dtype=float32>, 'Fare': <tf.Tensor 'Fare:0' shape=(None, 1) dtype=float32>, 'Embarked': <tf.Tensor 'Embarked:0' shape=(None, 1) dtype=string>, 'Sex': <tf.Tensor 'Sex:0' shape=(None, 1) dtype=string>, 'Pclass': <tf.Tensor 'Pclass:0' shape=(None, 1) dtype=int64>}\n",
      "Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'Age': <tf.Tensor 'Age:0' shape=(None, 1) dtype=float32>, 'Fare': <tf.Tensor 'Fare:0' shape=(None, 1) dtype=float32>, 'Embarked': <tf.Tensor 'Embarked:0' shape=(None, 1) dtype=string>, 'Sex': <tf.Tensor 'Sex:0' shape=(None, 1) dtype=string>, 'Pclass': <tf.Tensor 'Pclass:0' shape=(None, 1) dtype=int64>}\n",
      "Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'Age': <tf.Tensor 'Age:0' shape=(None, 1) dtype=float32>, 'Fare': <tf.Tensor 'Fare:0' shape=(None, 1) dtype=float32>, 'Embarked': <tf.Tensor 'Embarked:0' shape=(None, 1) dtype=string>, 'Sex': <tf.Tensor 'Sex:0' shape=(None, 1) dtype=string>, 'Pclass': <tf.Tensor 'Pclass:0' shape=(None, 1) dtype=int64>}\n",
      "Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'Age': <tf.Tensor 'inputs:0' shape=(None, 1) dtype=float32>, 'Fare': <tf.Tensor 'inputs_2:0' shape=(None, 1) dtype=float32>, 'Embarked': <tf.Tensor 'inputs_1:0' shape=(None, 1) dtype=string>, 'Sex': <tf.Tensor 'inputs_4:0' shape=(None, 1) dtype=string>, 'Pclass': <tf.Tensor 'inputs_3:0' shape=(None, 1) dtype=int64>}\n",
      "Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'Age': <tf.Tensor 'inputs:0' shape=(None, 1) dtype=float32>, 'Fare': <tf.Tensor 'inputs_2:0' shape=(None, 1) dtype=float32>, 'Embarked': <tf.Tensor 'inputs_1:0' shape=(None, 1) dtype=string>, 'Sex': <tf.Tensor 'inputs_4:0' shape=(None, 1) dtype=string>, 'Pclass': <tf.Tensor 'inputs_3:0' shape=(None, 1) dtype=int64>}\n",
      "Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'Age': <tf.Tensor 'inputs/Age:0' shape=(None, 1) dtype=float32>, 'Fare': <tf.Tensor 'inputs/Fare:0' shape=(None, 1) dtype=float32>, 'Embarked': <tf.Tensor 'inputs/Embarked:0' shape=(None, 1) dtype=string>, 'Sex': <tf.Tensor 'inputs/Sex:0' shape=(None, 1) dtype=string>, 'Pclass': <tf.Tensor 'inputs/Pclass:0' shape=(None, 1) dtype=int64>}\n",
      "Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'Age': <tf.Tensor 'inputs/Age:0' shape=(None, 1) dtype=float32>, 'Fare': <tf.Tensor 'inputs/Fare:0' shape=(None, 1) dtype=float32>, 'Embarked': <tf.Tensor 'inputs/Embarked:0' shape=(None, 1) dtype=string>, 'Sex': <tf.Tensor 'inputs/Sex:0' shape=(None, 1) dtype=string>, 'Pclass': <tf.Tensor 'inputs/Pclass:0' shape=(None, 1) dtype=int64>}\n",
      "Consider rewriting this model with the Functional API.\n",
      "INFO:tensorflow:Assets written to: ./flask/model/assets\n"
     ]
    }
   ],
   "source": [
    "keras.models.save_model(model, './tf_serving/model',save_format='tf')\n",
    "keras.models.save_model(model, './flask/model',save_format='tf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 Deploy Tensorflow Serving Docker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1A\u001b[1B\u001b[0G\u001b[?25l[+] Building 0.0s (0/2)                                                         \n",
      " => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.1s (6/6)                                                         \n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 36B                                        0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/tensorflow/serving:latest       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 239.99kB                                      0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [1/2] FROM docker.io/tensorflow/serving                         0.0s\n",
      "\u001b[0m\u001b[34m => [2/2] COPY ./model /models/model/1                                     0.0s\n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.1s (7/7) FINISHED                                                \n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 36B                                        0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/tensorflow/serving:latest       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 239.99kB                                      0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [1/2] FROM docker.io/tensorflow/serving                         0.0s\n",
      "\u001b[0m\u001b[34m => [2/2] COPY ./model /models/model/1                                     0.0s\n",
      "\u001b[0m\u001b[34m => exporting to image                                                     0.0s\n",
      "\u001b[0m\u001b[34m => => exporting layers                                                    0.0s\n",
      "\u001b[0m\u001b[34m => => writing image sha256:b781573fce45ca46e213706c07a4e21e8b1fe1f4b4f5e  0.0s\n",
      "\u001b[0m\u001b[34m => => naming to docker.io/library/tf_serving                              0.0s\n",
      "\u001b[0m\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!docker build --tag tf_serving ./tf_serving/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "732380b75a9a5be5dabe028fa934a82cf41f78b38de3cfbc79cf53430a12e1bd\r\n"
     ]
    }
   ],
   "source": [
    "!docker run --name exp3_tf_serving -p 8081:8501 -d tf_serving"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 Deploy Flask Docker Container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1A\u001b[1B\u001b[0G\u001b[?25l[+] Building 0.0s (2/2)                                                         \n",
      "\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.2s (2/3)                                                         \n",
      "\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 129B                                       0.0s\n",
      "\u001b[0m => [internal] load metadata for docker.io/library/python:3.7-slim         0.1s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.3s (2/3)                                                         \n",
      "\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 129B                                       0.0s\n",
      "\u001b[0m => [internal] load metadata for docker.io/library/python:3.7-slim         0.2s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.5s (2/3)                                                         \n",
      "\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 129B                                       0.0s\n",
      "\u001b[0m => [internal] load metadata for docker.io/library/python:3.7-slim         0.4s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.6s (2/3)                                                         \n",
      "\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 129B                                       0.0s\n",
      "\u001b[0m => [internal] load metadata for docker.io/library/python:3.7-slim         0.5s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.8s (2/3)                                                         \n",
      "\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 129B                                       0.0s\n",
      "\u001b[0m => [internal] load metadata for docker.io/library/python:3.7-slim         0.7s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.9s (2/3)                                                         \n",
      "\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 129B                                       0.0s\n",
      "\u001b[0m => [internal] load metadata for docker.io/library/python:3.7-slim         0.9s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 1.1s (2/3)                                                         \n",
      "\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 129B                                       0.0s\n",
      "\u001b[0m => [internal] load metadata for docker.io/library/python:3.7-slim         1.0s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 1.2s (2/3)                                                         \n",
      "\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 129B                                       0.0s\n",
      "\u001b[0m => [internal] load metadata for docker.io/library/python:3.7-slim         1.2s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 1.4s (2/3)                                                         \n",
      "\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 129B                                       0.0s\n",
      "\u001b[0m => [internal] load metadata for docker.io/library/python:3.7-slim         1.3s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 1.5s (2/3)                                                         \n",
      "\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 129B                                       0.0s\n",
      "\u001b[0m => [internal] load metadata for docker.io/library/python:3.7-slim         1.5s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 1.7s (2/3)                                                         \n",
      "\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 129B                                       0.0s\n",
      "\u001b[0m => [internal] load metadata for docker.io/library/python:3.7-slim         1.6s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 1.8s (2/3)                                                         \n",
      "\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 129B                                       0.0s\n",
      "\u001b[0m => [internal] load metadata for docker.io/library/python:3.7-slim         1.8s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 2.0s (2/3)                                                         \n",
      "\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 129B                                       0.0s\n",
      "\u001b[0m => [internal] load metadata for docker.io/library/python:3.7-slim         1.9s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 2.1s (2/3)                                                         \n",
      "\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 129B                                       0.0s\n",
      "\u001b[0m => [internal] load metadata for docker.io/library/python:3.7-slim         2.1s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 2.3s (2/3)                                                         \n",
      "\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 129B                                       0.0s\n",
      "\u001b[0m => [internal] load metadata for docker.io/library/python:3.7-slim         2.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 2.4s (2/3)                                                         \n",
      "\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 129B                                       0.0s\n",
      "\u001b[0m => [internal] load metadata for docker.io/library/python:3.7-slim         2.4s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 2.6s (2/3)                                                         \n",
      "\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 129B                                       0.0s\n",
      "\u001b[0m => [internal] load metadata for docker.io/library/python:3.7-slim         2.5s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 2.7s (2/3)                                                         \n",
      "\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 129B                                       0.0s\n",
      "\u001b[0m => [internal] load metadata for docker.io/library/python:3.7-slim         2.7s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 2.9s (2/3)                                                         \n",
      "\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 129B                                       0.0s\n",
      "\u001b[0m => [internal] load metadata for docker.io/library/python:3.7-slim         2.8s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 3.0s (2/3)                                                         \n",
      "\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 129B                                       0.0s\n",
      "\u001b[0m => [internal] load metadata for docker.io/library/python:3.7-slim         3.0s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 3.2s (2/3)                                                         \n",
      "\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 129B                                       0.0s\n",
      "\u001b[0m => [internal] load metadata for docker.io/library/python:3.7-slim         3.1s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 3.3s (2/3)                                                         \n",
      "\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 129B                                       0.0s\n",
      "\u001b[0m => [internal] load metadata for docker.io/library/python:3.7-slim         3.3s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 3.5s (2/3)                                                         \n",
      "\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 129B                                       0.0s\n",
      "\u001b[0m => [internal] load metadata for docker.io/library/python:3.7-slim         3.4s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 3.6s (2/3)                                                         \n",
      "\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 129B                                       0.0s\n",
      "\u001b[0m => [internal] load metadata for docker.io/library/python:3.7-slim         3.6s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 3.8s (2/3)                                                         \n",
      "\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 129B                                       0.0s\n",
      "\u001b[0m => [internal] load metadata for docker.io/library/python:3.7-slim         3.7s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 3.9s (2/3)                                                         \n",
      "\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 129B                                       0.0s\n",
      "\u001b[0m => [internal] load metadata for docker.io/library/python:3.7-slim         3.9s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 4.1s (2/3)                                                         \n",
      "\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 129B                                       0.0s\n",
      "\u001b[0m => [internal] load metadata for docker.io/library/python:3.7-slim         4.0s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 4.2s (2/3)                                                         \n",
      "\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 129B                                       0.0s\n",
      "\u001b[0m => [internal] load metadata for docker.io/library/python:3.7-slim         4.2s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 4.4s (2/3)                                                         \n",
      "\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 129B                                       0.0s\n",
      "\u001b[0m => [internal] load metadata for docker.io/library/python:3.7-slim         4.3s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 4.5s (9/10)                                                        \n",
      "\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 129B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/python:3.7-slim         4.3s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 240.94kB                                      0.0s\n",
      "\u001b[0m\u001b[34m => [1/5] FROM docker.io/library/python:3.7-slim@sha256:de75b6dc5e4040a59  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [2/5] WORKDIR /usr/src/app                                      0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [3/5] RUN pip install -i http://pypi.douban.com/simple/ --trus  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [4/5] COPY app.py .                                             0.0s\n",
      "\u001b[0m\u001b[34m => [5/5] COPY ./model ./model                                             0.0s\n",
      "\u001b[0m => exporting to image                                                     0.0s\n",
      "\u001b[34m => => exporting layers                                                    0.0s\n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 4.5s (10/10) FINISHED                                              \n",
      "\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 129B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/python:3.7-slim         4.3s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 240.94kB                                      0.0s\n",
      "\u001b[0m\u001b[34m => [1/5] FROM docker.io/library/python:3.7-slim@sha256:de75b6dc5e4040a59  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [2/5] WORKDIR /usr/src/app                                      0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [3/5] RUN pip install -i http://pypi.douban.com/simple/ --trus  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [4/5] COPY app.py .                                             0.0s\n",
      "\u001b[0m\u001b[34m => [5/5] COPY ./model ./model                                             0.0s\n",
      "\u001b[0m\u001b[34m => exporting to image                                                     0.0s\n",
      "\u001b[0m\u001b[34m => => exporting layers                                                    0.0s\n",
      "\u001b[0m\u001b[34m => => writing image sha256:21b3fe8edd9ef2c92fe2038edc5660ab3364dedb31f50  0.0s\n",
      "\u001b[0m\u001b[34m => => naming to docker.io/library/flask                                   0.0s\n",
      "\u001b[0m\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!docker build --tag flask ./flask/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4f91390a3bc52036a5045c71511f407876c3dcad162b0dee9e6c8013d109e865\r\n"
     ]
    }
   ],
   "source": [
    "!docker run --name exp3_flask -p 8080:8080 -d flask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 Compare Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from tqdm.auto import tqdm\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('./titanic_test.csv',index_col=0)\n",
    "test_data = test_data[[\n",
    "    'Age','Fare','Embarked','Sex','Pclass'\n",
    "]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "male      266\n",
       "female    152\n",
       "Name: Sex, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.Sex.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['male', 'female'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.Sex.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0195f2604804b4b99c3d975e2840a14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=418), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('Used', 4.414155960083008, 'seconds')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tensorflow serving\n",
    "start = time()\n",
    "for _, row in tqdm(test_data.iterrows(), total=test_data.shape[0]):\n",
    "    item = row.to_dict()\n",
    "    for key in item:\n",
    "        if 'float' in str(type(item[key])):\n",
    "            item[key] = float(item[key])\n",
    "        if 'int' in str(type(item[key])):\n",
    "            item[key] = int(item[key])\n",
    "        \n",
    "        item[key] = [item[key]]\n",
    "            \n",
    "    res = requests.post('http://localhost:8081/v1/models/model:predict',json = {'instances': [item]})\n",
    "    res.raise_for_status()\n",
    "    \n",
    "end = time()\n",
    "'Used', end-start, 'seconds'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c270231c7ac34f78a4ec7a1976422659",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=418), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('Used', 28.770965099334717, 'seconds')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# flask with model\n",
    "start = time()\n",
    "for _, row in tqdm(test_data.iterrows(), total=test_data.shape[0]):\n",
    "    item = row.to_dict()\n",
    "    for key in item:\n",
    "        if 'float' in str(type(item[key])):\n",
    "            item[key] = float(item[key])\n",
    "        if 'int' in str(type(item[key])):\n",
    "            item[key] = int(item[key])\n",
    "\n",
    "    res = requests.post('http://localhost:8080/model',json = item)\n",
    "    res.raise_for_status()\n",
    "end = time()\n",
    "'Used', end-start, 'seconds'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exp3_flask\r\n"
     ]
    }
   ],
   "source": [
    "!docker stop exp3_flask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exp3_flask\r\n"
     ]
    }
   ],
   "source": [
    "!docker rm exp3_flask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exp3_tf_serving\r\n"
     ]
    }
   ],
   "source": [
    "!docker stop exp3_tf_serving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exp3_tf_serving\r\n"
     ]
    }
   ],
   "source": [
    "!docker rm exp3_tf_serving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
